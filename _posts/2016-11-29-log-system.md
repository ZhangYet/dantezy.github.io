---
layout: post
title: "Enjoy 日志收集系统"
comments: true
---
—— 这是平台工程师小马的纪录，他纪录了 ENJOY 后台日志系统的变迁，为的是总结他十一以来的工作（以及模仿希罗多德装逼）

## 深渊混沌，无可名状
我刚来 ENJOY 的时候，我们只有A机房，并没有一个日志收集中心。 Apollo 的日志保存在它们自己的服务器上面，都是纯文本，保存若改天后抛弃掉。 Prometheus 更惨，它前面有一个 nginx 做 LB，但是这个 nginx 的 access log 并没有被认真对待过，prometheus 本身的 log，额，既没有分割，也没有集中处理。就堆在那里，没事没人看，有事也看不出来。

现在回想起来，当时的日志系统就好像一个深渊，看一眼都会掉 san 值， 非常克苏鲁。

## 矇昧始觉，雪夜曙光
随着 eru 平台的上线，我们终于开始有了一套相对完善的日志收集系统。 eru 平台上主要收集了两种日志：容器产生的日志和 elb 的 access log 。当时 elb 日志系统的体系相当简单：

![eru1日志收集系统](http://zhangyet.github.io/public/image/eru1-log-system.png)

这个架构相当简单明了。但是存在一个问题：agent 到日志收集服务器之间缺乏一个缓存（实际上 agent 是有一个比较小的缓存的，但一般没有开），而日志收集服务器作为一个单点，是整个系统最薄弱的一环。整个问题一直困扰着 eru1 。

最早的日志收集服务是用 logstash 做的。 logstash 存在两个问题：1. grok 难写（不多说，说起来都是泪，谁写谁知道）；2. 重启慢，而且当时还遇到一天死几次的情况，让人不得安生。 所以我着手的第一个工作是选择 logstash 的替代品。在各种日志收集工具中，最终我们选择了 heka，这很大一部分原因是宜信的 lain 也在用它。 其实也考虑过知乎的 kids，无奈的是，知乎自己弃坑之余，kids 自己的可扩展性并不好（heka 可以写 lua 脚本）。

最后 eru1 的日志收集服务就采用了 heka， 但当时存在两个问题：1. heka 处理时间时候有点问题，它拿到的是零时区的时间戳，这导致了你看到的 2016-11-29.log 的日志，其实是 2016-11-29 08:00:00 ~ 2016-11-30 07:59:59; 2. heka 处理 elb 数据的 docoder 插件经常会死掉，很尴尬的是，只会死这个插件，想监控都很困难。

随着接入日志的增多，我们开始将日志输出到 ES。 所以为了解决上一段提及的问题2， 我写了一个定时程序，定时访问 ES, 拿最新的时间戳，如果这个时间落后实际时间5分钟，那就重启 heka。 这是一个粗糙的方法。

值得注意的是，这个时候，我们依然保持了 agent 和 elb 直接向 日志收集系统发日志的架构。这导致后来的一场灾难。

## 一元复始，万象初开
eru1 日志解决不了的如果问题给我们带来了若干困扰，痛定思痛之余，我们设计了 eru2 的日志系统。eru2 日志收集系统最初的设计如下图。

![eru2日志收集系统(version 1)](http://zhangyet.github.io/public/image/eru2-log-system-ver1.png)

Kafka 在其中扮演了非常重要的角色。有了 Kafka 做缓冲，即使日志收集机器有什么三长两短，我们依然可以补回日志。

在十一长假里面，回到家乡，没有女朋友，也没有 PS4 的程序员小马决定重整日志系统的 heka 插件。 在此之前，他曾经打算用 logstash 替代 heka 作为日志收集服务。 但无奈，grok 还是太难写了，而经过 erulb3 开发的小马，已经能够熟练进行 lua 开发了，所以他重新选择了 heka 作为日志收集工具。于此同时，他用一种简单粗暴的方法解决了 heka 时间戳的问题：既然 heka 总是拿到零时区的时间戳，那我代码里面再把8小时加上去，那总归是东8区的时间了吧。

在十一假期结束的时候，小马已经为 eru2 的日志收集系统构建了一组 heka 插件，eru2 的日志收集已经顺利运作起来了，一起看起来都是如此美好。但是没有人想到，命运的阴谋已经在前方等着他们了。

## 混乱之治
十月份开始，我们的工作重点落在迁移 apollo 一事上。而在十月中旬，一个潇湘夜雨的晚上，apollo 的 mq 开始疯狂吐日志，然后龙老板发现落地的日志有巨大的延时：晚上7点看到落地的日志还是5点多的日志。更要命的是，在 kafka 上面看到对应的 topic 的 LAG 始终在增大， Offset 一直没有移动。

这里其实包含了三个问题：1. heka 消费了 kafka 的信息之后，并不会改变 kafka 的 Offset， 这是 heka kafka 插件的锅； 2. heka 的日志处理能力； 3. apollo 的日志吐疯了。

为了解决问题1，我在那个周末把 C2 的日志收集工具从 hekad 换成了 logstash，但是在龙老板和小羊把 apollo 的日志给控制住之前，换了  logstash 也无能为力。

正所谓“正入万山圈子中，一山放过一山拦”，时间接近双十一，日志系统依然混乱。而 eru1 日志系统的遗留问题，引发了[一次药丸的线上错误](http://blog.ricebook.net/a-pill-error-online/),  这次事故的原因简单概括来说，就是：容器产生了大量日志，heka 处理不来， agent 往 heka 这一段堵死了，然后容器到 agent 这一段也堵死了，之后容器就被堵死了。[注1]

为了确保双十一，我们再次改造了 eru1 的日志收集系统。
![eru1日志收集系统(双十一改版)](http://zhangyet.github.io/public/image/eru1-log-system-1111.png)

这次的改动是让容器先将容器打到本地的 rsyslog ，后者配置缓存队列，确保1. 有足够能力消化容器产生的日志；2. 在日志收集服务器挂掉的情况下，支持住，尽量不丢日志。这个改动是成功的，我们成功度过了双十一。

但是，从整体来看，整个日志系统到了最危险的时候，C1 的情况可以先放在一边，C2 的 agent log 和 elb access log 的处理方式，多种日志收集工具并存(rsyslog, logstash和heka)。可以说是乱象横生。

##  如切如磋，如琢如磨
为了结束这种混乱的情况，前一周和 Flex，菊总讨论，我们重新设计了 C2 的日志收集系统。

![eru2日志收集系统(version 2)](http://zhangyet.github.io/public/image/eru2-log-system-ver2.png)
