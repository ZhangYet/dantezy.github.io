<h1 id="tinylfu-一种缓存策略">TinyLFU 一种缓存策略</h1>

<p>读 <a href="https://blog.dgraph.io/post/caching-in-go/">The State of Caching in Go</a> 的时候知道了 <a href="https://github.com/ben-manes/caffeine">caffeine</a>， 知道它是基于 TinyLFU 实现的，所以找了<a href="https://arxiv.org/pdf/1512.00727.pdf">文章</a>来看看。</p>

<h2 id="导论">导论</h2>

<p>缓存的底层原理是 <a href="https://en.wikipedia.org/wiki/Central_tendency">locality 假设</a>（就像统计学家通常假设正态分布一样）。而这种 locality 是可以通过频次统计来估计出来的。</p>

<p>命中率最高的策略就是 LFU，但是 LFU 有两个缺点：1. 需要维护比较大的元数据（比如说 key 的频数统计，缓存根据元数据来决定那些 key 需要清退）；2. 频数变化可能会很快。</p>

<p>与 LFU 相对的是 LRU， LRU 保证最新的 key 在前面，淘汰最旧的 key。LRU 效率会更高，但是需要更大的缓存空间才能达到 LFU 的命中率。(但是我自己做了个实验，发现并非如此：在 zipf 分布的情况下，LFU 的命中率比 LRU 的命中率高不了多少，但是耗时明显比 LRU 高，在均匀分布的条件下，两者的表现都很差， 测试用的代码在<a href="https://github.com/ZhangYet/ahotori/tree/master/Demos/CacheTest">这里</a>， 当然我这里的结论可能不正确，因为我的测试可能不够全面，无论如何，我觉得在大部分场景下， LRU 都比 LFU 有优势——命中率差不多，速度快，实现更简单)。</p>

<p><code class="highlighter-rouge">TinyLFU</code> 的改进之处在于：</p>

<ol>
  <li>对某个 key 是否放入缓存，有一个准入策略，需要判断把 key 放进缓存有利才会放；</li>
  <li>更紧凑的数据结构；</li>
</ol>

<h2 id="相关工作">相关工作</h2>

<p>这个章节提到各种 LFU 的改进方案。另外提及了一些近似计数方案(approximate counting architecture)：</p>

<ul>
  <li><code class="highlighter-rouge">TinyLFU</code> 不考虑抽样方法，因为抽样方法需要 keys 有 explicit representation 这个增加成本。</li>
  <li><a href="https://web.stanford.edu/~montanar/RESEARCH/FILEPAP/sigmetrics08_final.pdf">Counter Braids</a> 可以减少 meta data 的尺寸，但是解码麻烦，所以也不考虑。</li>
  <li>综合比较了几种 multi hash sketches，最后选择了 <a href="https://cloud.tencent.com/developer/article/1136056">Counting bloom filter</a> 加上 <a href="http://www.cs.technion.ac.il/~gilga/CS-2014-04.pdf">minimal increment scheme</a>，这个方案。</li>
</ul>

<p>（以上文献我都没读过——一篇文献带出无数文献，要真读了我得死去啊，这一方面也反映了 IT 从业人员的艰辛。）</p>

<h2 id="tinylfu-架构">TinyLFU 架构</h2>

<p>总的来说就是每次需要淘汰 key 的时候，就是拿出新的 key 取它在计数器里面的值，跟需要淘汰的 key 的值比较，如果新的 key 的值更大，那么就淘汰旧的（但我不明白怎能取到新的 key 的计数，就算可以吧，这个新的 key 的计数为什么可以代表它的频数）。</p>

<h3 id="近似计数">近似计数</h3>

<p>这里采用了 minimal increment CBF。支持两种方法：</p>

<ol>
  <li><code class="highlighter-rouge">Estimate</code>: 计算 k 个不同的 hash 值，以 hash 值为索引，找到对应的计数器，然后返回最小的值。</li>
  <li><code class="highlighter-rouge">Add</code>: 计算 k 个不同的 hash 值，以此为索引，增加值最小的计数器的值（如果值最小的计数器有多个，则增加多个计数器的值）。</li>
</ol>

<p>因为采用了 minimal increment 策略，所以不支持减少计数，但是有利于统计高频的 key，详细的分析可以看<a href="http://www.cs.technion.ac.il/~gilga/CS-2014-04.pdf">这篇文献</a>（然而我还没有看）。</p>

<h3 id="更新机制freshness-mechanism">更新机制(freshness mechanism)</h3>

<p>3.3.2 两条引理就是说“频数接近期望”，这都能写一节，明显是欺负 CS 的人概率学读得少啊。</p>

<p>但是这一节（3.3）我没有怎么读懂，为什么要在达到一定的 sample size 之后除以2，看起来挺莫名其妙的。</p>

<h2 id="总结">总结</h2>

<p>从总体思路上，<code class="highlighter-rouge">TinyLRU</code> 就是换用了一种更高效的方法（且在空间和时间上平衡）去估算 key 的分布。这让我想起2017年，用机器学习去估 key 分布从而优化数据库索引的<a href="https://arxiv.org/abs/1712.01208">这篇文章</a>。有可能这是一种新套路：通过估变量分布来优化性能，或者我们应该搞一个公共组件专门来做这种事情。</p>
